import openai
import os
from typing import List, Dict, Any
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")

class LLMRequester:
    def __init__(self, api_key: str = None, model: str = "gpt-4.1-mini", base_url: str = None):
        """
        LLM ëª¨ë¸ê³¼ ì†Œí†µí•˜ê¸° ìœ„í•œ ìš”ì²­ í´ë˜ìŠ¤
        
        Args:
            api_key: OpenAI API í‚¤ (ì—†ìœ¼ë©´ .envì—ì„œ OPENAI_API_KEY ì‚¬ìš©)
            model: ì‚¬ìš©í•  ëª¨ë¸ëª…
            base_url: OpenAI API Base URL (ì—†ìœ¼ë©´ .envì—ì„œ OPENAI_BASE_URL ì‚¬ìš©)
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL")
        
        if not self.api_key:
            raise ValueError("OpenAI API keyê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ê±°ë‚˜ api_key íŒŒë¼ë¯¸í„°ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.")
        
        client_kwargs = {"api_key": self.api_key}
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
        
        self.client = OpenAI(**client_kwargs)
        self.model = model
        self.conversation_history = []
        
        # ì„¤ì •ëœ í™˜ê²½ë³€ìˆ˜ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        print(f"ğŸ¤– LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - Model: {self.model}")
        print(f"   - API Key: {'âœ… ì„¤ì •ë¨' if self.api_key else 'âŒ ë¯¸ì„¤ì •'}")
        print(f"   - Base URL: {self.base_url if self.base_url else 'ê¸°ë³¸ê°’ ì‚¬ìš©'}")
    
    def send_message(self, message: str, system_prompt: str = None, **kwargs) -> str:
        """
        LLMì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŠµë‹ˆë‹¤.
        
        Args:
            message: ì‚¬ìš©ì ë©”ì‹œì§€
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„ íƒì‚¬í•­)
            **kwargs: ì¶”ê°€ OpenAI API íŒŒë¼ë¯¸í„° (temperature, max_tokens ë“±)
            
        Returns:
            ëª¨ë¸ì˜ ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        try:
            messages = []
            
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            
            messages.extend(self.conversation_history)
            messages.append({"role": "user", "content": message})
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            api_params = {
                "model": self.model,
                "messages": messages,
                "max_tokens": kwargs.get("max_tokens", int(os.getenv("MAX_TOKENS", 1000))),
                "temperature": kwargs.get("temperature", float(os.getenv("TEMPERATURE", 0.7))),
                "top_p": kwargs.get("top_p", 1.0),
                "frequency_penalty": kwargs.get("frequency_penalty", 0),
                "presence_penalty": kwargs.get("presence_penalty", 0)
            }
            
            response = self.client.chat.completions.create(**api_params)
            
            assistant_response = response.choices[0].message.content
            
            self.conversation_history.append({"role": "user", "content": message})
            self.conversation_history.append({"role": "assistant", "content": assistant_response})
            
            return assistant_response
            
        except Exception as e:
            return f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.conversation_history = []
    
    def get_history(self) -> List[Dict[str, str]]:
        """í˜„ì¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.conversation_history.copy()
    
    def change_model(self, model: str):
        """ì‚¬ìš©í•  ëª¨ë¸ì„ ë³€ê²½í•©ë‹ˆë‹¤."""
        self.model = model
        print(f"ğŸ”„ ëª¨ë¸ ë³€ê²½: {model}")
    
    def change_base_url(self, base_url: str):
        """Base URLì„ ë³€ê²½í•˜ê³  í´ë¼ì´ì–¸íŠ¸ë¥¼ ì¬ìƒì„±í•©ë‹ˆë‹¤."""
        self.base_url = base_url
        client_kwargs = {"api_key": self.api_key}
        if self.base_url:
            client_kwargs["base_url"] = self.base_url
        self.client = OpenAI(**client_kwargs)
        print(f"ğŸ”„ Base URL ë³€ê²½: {base_url}")
    
    def get_env_info(self) -> dict:
        """í˜„ì¬ í™˜ê²½ë³€ìˆ˜ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return {
            "api_key_set": bool(self.api_key),
            "base_url": self.base_url,
            "model": self.model,
            "max_tokens": int(os.getenv("MAX_TOKENS", 1000)),
            "temperature": float(os.getenv("TEMPERATURE", 0.7)),
        }


def load_env_config():
    """
    .env íŒŒì¼ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•˜ê³  ê²€ì¦í•©ë‹ˆë‹¤.
    
    Returns:
        dict: ë¡œë“œëœ í™˜ê²½ë³€ìˆ˜ ì„¤ì •
    """
    load_dotenv()
    
    config = {
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY"),
        "OPENAI_BASE_URL": os.getenv("OPENAI_BASE_URL"),
        "DEFAULT_MODEL": os.getenv("DEFAULT_MODEL", "gpt-4.1-mini"),
    }
    
    return config


def simple_chat_example():
    """ê¸°ë³¸ì ì¸ ì±„íŒ… ì˜ˆì‹œ"""
    print("=== LLM ê°„ë‹¨í•œ ì±„íŒ… ì˜ˆì‹œ ===")
    
    try:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê¸°ë³¸ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        default_model = os.getenv("DEFAULT_MODEL", "gpt-4.1-mini")
        llm = LLMRequester(model=default_model)
        
        system_prompt = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."
        
        response = llm.send_message(
            "ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
            system_prompt=system_prompt
        )
        
        print(f"\nì‚¬ìš©ì: ì•ˆë…•í•˜ì„¸ìš”! íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œì˜ ì°¨ì´ì ì„ ì•Œë ¤ì£¼ì„¸ìš”.")
        print(f"LLM: {response}\n")
        
        response2 = llm.send_message("ê·¸ëŸ¼ ì–¸ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ì–¸ì œ íŠœí”Œì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì„ê¹Œìš”?")
        print(f"ì‚¬ìš©ì: ê·¸ëŸ¼ ì–¸ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ê³  ì–¸ì œ íŠœí”Œì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì„ê¹Œìš”?")
        print(f"LLM: {response2}")
        
    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ .env íŒŒì¼ì„ ìƒì„±í•˜ê³  OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    print("ğŸ”§ í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸...")
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • í™•ì¸
    config = load_env_config()
        
        simple_chat_example() 